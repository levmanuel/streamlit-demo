import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from rank_bm25 import BM25Okapi
import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')

st.set_page_config(layout="wide")
st.title("üïµÔ∏è Analyse des M√©thodes de Vectorisation de Texte")

# Configuration avanc√©e
st.sidebar.header("Configuration BM25")
k1 = st.sidebar.slider("Param√®tre BM25 k1", 1.0, 2.0, 1.5)
b = st.sidebar.slider("Param√®tre BM25 b", 0.0, 1.0, 0.75)

# Exemples de phrases plus complexes
DEFAULT_TEXT = """L'intelligence artificielle transforme l'industrie m√©dicale en automatisant le diagnostic des maladies.
Les algorithmes d'apprentissage profond permettent d'analyser des images m√©dicales avec une pr√©cision in√©gal√©e.
L'IA √©thique est un domaine en pleine croissance, visant √† r√©duire les biais dans les mod√®les pr√©dictifs.
Les mod√®les de langage comme GPT-4 soul√®vent des questions √©thiques sur la confidentialit√© des donn√©es.
Le r√©chauffement climatique impacte la sant√© publique en augmentant les maladies respiratoires.
Les √©nergies renouvelables sont essentielles pour lutter contre le changement climatique.
La cybers√©curit√© est devenue une priorit√© pour prot√©ger les donn√©es sensibles dans le secteur m√©dical."""

# Interface utilisateur
st.header("Entr√©e des donn√©es")

sample_texts = st.text_area("Phrases d'exemple (une par ligne)", DEFAULT_TEXT, height=200)
query = st.text_input("Requ√™te de recherche", "IA √©thique sant√© m√©dicale")

# Pr√©traitement
texts = [text.strip() for text in sample_texts.split("\n") if text.strip()]
french_stopwords = stopwords.words('french')

def preprocess(text):
    return ' '.join([word.lower() for word in text.split() 
                    if word.lower() not in french_stopwords and len(word) > 2])

# Calculs des similarit√©s
if texts:
    processed_texts = [preprocess(text) for text in texts]
    processed_query = preprocess(query)
    
    # CountVectorizer
    count_vec = CountVectorizer()
    count_matrix = count_vec.fit_transform(processed_texts)
    
    # TF-IDF
    tfidf_vec = TfidfVectorizer()
    tfidf_matrix = tfidf_vec.fit_transform(processed_texts)
    
    # BM25
    tokenized_corpus = [doc.split() for doc in processed_texts]
    bm25 = BM25Okapi(tokenized_corpus, k1=k1, b=b)
    tokenized_query = processed_query.split()
    
    # Scores avanc√©s
    count_sims = cosine_similarity(count_vec.transform([processed_query]), count_matrix)
    tfidf_sims = cosine_similarity(tfidf_vec.transform([processed_query]), tfidf_matrix)
    bm25_scores = bm25.get_scores(tokenized_query)
    top_n_docs = bm25.get_top_n(tokenized_query, texts, n=3)

    # Affichage des r√©sultats
    st.header("üîç R√©sultats d√©taill√©s")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("CountVectorizer")
        st.write("Similarit√© cosinus avec la requ√™te:")
        st.bar_chart(pd.DataFrame({
            'Textes': [f"Doc {i+1}" for i in range(len(texts))],
            'Similarit√©': count_sims[0]
        }).set_index('Textes'))
    
    with col2:
        st.subheader("TF-IDF")
        st.write("Similarit√© cosinus avec la requ√™te:")
        st.bar_chart(pd.DataFrame({
            'Textes': [f"Doc {i+1}" for i in range(len(texts))],
            'Similarit√©': tfidf_sims[0]
        }).set_index('Textes'))
    
    with col3:
        st.subheader("BM25")
        st.write("Scores bruts BM25:")
        st.bar_chart(pd.DataFrame({
            'Textes': [f"Doc {i+1}" for i in range(len(texts))],
            'Score': bm25_scores
        }).set_index('Textes'))
    
    # Top documents BM25
    st.subheader("üìå Top 3 des documents pertinents (BM25)")
    for i, doc in enumerate(top_n_docs):
        st.markdown(f"{i+1}. {doc}")
    
    # Explications techniques
    st.header("üìö Explications des m√©triques")
    
    st.markdown("""
    **M√©triques utilis√©es :**
    1. **Similarit√© Cosinus** : Mesure la similarit√© directionnelle entre vecteurs
    2. **Scores BM25** : Algorithme probabiliste optimis√© pour la recherche documentaire
    3. **Top N Documents** : S√©lection des documents les plus pertinents selon BM25

    **Diff√©rences cl√©s :**
    - üßÆ **CountVectorizer** : Comptage brut des occurrences
    - üìà **TF-IDF** : Pond√©ration par importance statistique
    - üèÜ **BM25** : 
        - P√©nalise les documents longs (param√®tre b)
        - Non-linearit√© dans les fr√©quences (param√®tre k1)
        - Optimis√© pour le ranking de r√©sultats
    """)

else:
    st.warning("‚ö†Ô∏è Veuillez entrer au moins une phrase valide!")