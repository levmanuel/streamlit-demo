import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from rank_bm25 import BM25Okapi
import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')

st.set_page_config(layout="wide")
st.title("üïµÔ∏è‚ôÇÔ∏è Analyse Comparative de M√©thodes de Vectorisation Texte")

# Configuration avanc√©e
st.sidebar.header("Configuration")
max_features = st.sidebar.slider("Nombre maximal de features", 10, 1000, 200)
analyzer = st.sidebar.selectbox("Analyzer", ["word", "char", "char_wb"])
k1 = st.sidebar.slider("Param√®tre BM25 k1", 1.0, 2.0, 1.5)
b = st.sidebar.slider("Param√®tre BM25 b", 0.0, 1.0, 0.75)

# Exemples de phrases plus complexes
DEFAULT_TEXT = """L'apprentissage profond r√©volutionne l'analyse des donn√©es m√©dicales.
Les mod√®les de langage √† grande √©chelle posent des d√©fis √©thiques importants.
Le r√©chauffement climatique entra√Æne des ph√©nom√®nes m√©t√©orologiques extr√™mes.
L'√©conomie circulaire promet une croissance durable mais n√©cessite des investissements initiaux.
Les cyberattaques sophistiqu√©es ciblent les infrastructures critiques mondialement."""

# Interface utilisateur
st.header("Entr√©e des donn√©es")

def plot_heatmap(matrix, features, title):
    plt.figure(figsize=(12, 8))
    sns.heatmap(matrix[:5], annot=True, fmt=".2f", cmap="YlGnBu",
                xticklabels=features, yticklabels=[f"Doc {i+1}" for i in range(len(matrix[:5]))])
    plt.title(title)
    st.pyplot(plt)

sample_texts = st.text_area("Phrases d'exemple (une par ligne)", DEFAULT_TEXT, height=150)
query = st.text_input("Requ√™te de recherche", "mod√®les climatiques √©thiques donn√©es")

# Pr√©traitement
texts = [text.strip() for text in sample_texts.split("\n") if text.strip()]
french_stopwords = stopwords.words('french')

def preprocess(text):
    return ' '.join([word.lower() for word in text.split() 
                    if word.lower() not in french_stopwords and len(word) > 2])

# Calculs des similarit√©s
if texts:
    processed_texts = [preprocess(text) for text in texts]
    processed_query = preprocess(query)
    
    # Vectorisation
    count_vec = CountVectorizer(max_features=max_features, analyzer=analyzer)
    count_matrix = count_vec.fit_transform(processed_texts)
    
    tfidf_vec = TfidfVectorizer(max_features=max_features, analyzer=analyzer)
    tfidf_matrix = tfidf_vec.fit_transform(processed_texts)
    
    # BM25
    tokenized_corpus = [doc.split() for doc in processed_texts]
    bm25 = BM25Okapi(tokenized_corpus, k1=k1, b=b)
    tokenized_query = processed_query.split()
    
    # Scores avanc√©s
    count_sims = cosine_similarity(count_vec.transform([processed_query]), count_matrix)
    tfidf_sims = cosine_similarity(tfidf_vec.transform([processed_query]), tfidf_matrix)
    bm25_scores = bm25.get_scores(tokenized_query)
    top_n_docs = bm25.get_top_n(tokenized_query, texts, n=3)

    # Affichage des r√©sultats
    st.header("üîç R√©sultats d√©taill√©s")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("CountVectorizer")
        st.write("Similarit√© cosinus avec la requ√™te:")
        st.bar_chart(pd.DataFrame({
            'Textes': [f"Doc {i+1}" for i in range(len(texts))],
            'Similarit√©': count_sims[0]
        }).set_index('Textes'))
    
    with col2:
        st.subheader("TF-IDF")
        st.write("Similarit√© cosinus avec la requ√™te:")
        st.bar_chart(pd.DataFrame({
            'Textes': [f"Doc {i+1}" for i in range(len(texts))],
            'Similarit√©': tfidf_sims[0]
        }).set_index('Textes'))
    
    with col3:
        st.subheader("BM25")
        st.write("Scores bruts BM25:")
        st.bar_chart(pd.DataFrame({
            'Textes': [f"Doc {i+1}" for i in range(len(texts))],
            'Score': bm25_scores
        }).set_index('Textes'))
    
    # Top documents BM25
    st.subheader("üìå Top 3 des documents pertinents (BM25)")
    for i, doc in enumerate(top_n_docs):
        st.markdown(f"{i+1}. {doc}")
    
    # Explications techniques
    st.header("üìö Explications des m√©triques")
    
    st.markdown("""
    **M√©triques utilis√©es :**
    1. **Similarit√© Cosinus** : Mesure la similarit√© directionnelle entre vecteurs
    2. **Scores BM25** : Algorithme probabiliste optimis√© pour la recherche documentaire
    3. **Top N Documents** : S√©lection des documents les plus pertinents selon BM25

    **Diff√©rences cl√©s :**
    - üßÆ **CountVectorizer** : Comptage brut des occurrences
    - üìà **TF-IDF** : Pond√©ration par importance statistique
    - üèÜ **BM25** : 
        - P√©nalise les documents longs (param√®tre b)
        - Non-linearit√© dans les fr√©quences (param√®tre k1)
        - Optimis√© pour le ranking de r√©sultats
    """)

else:
    st.warning("‚ö†Ô∏è Veuillez entrer au moins une phrase valide!")

