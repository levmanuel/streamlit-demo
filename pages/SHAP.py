import streamlit as st
import pandas as pd
import shap
import matplotlib.pyplot as plt
import numpy as np
from sklearn.datasets import fetch_california_housing
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split

st.set_page_config(page_title="SHAP & IA - Explicabilit√©", layout="wide")

st.title("üß† Explicabilit√© locale et globale avec SHAP")
st.write("""
Cette application explore les concepts d‚Äô**explicabilit√© globale et locale** √† l‚Äôaide de **SHAP**.
Nous utilisons un mod√®le de **Random Forest** sur le dataset *California Housing* pour pr√©dire le prix moyen d‚Äôune maison.
""")

# ------------------------------------
st.header("üì¶ 1. Chargement et pr√©paration des donn√©es")
@st.cache_data
def load_data():
    data = fetch_california_housing(as_frame=True)
    return data.data, data.target

X, y = load_data()
st.write("Aper√ßu des donn√©es :")
st.dataframe(X.head())

# ------------------------------------
st.header("üß† 2. Mod√®le utilis√©")
st.markdown("""
Nous utilisons un mod√®le **Random Forest Regressor** de Scikit-learn :
- `n_estimators = 100`
- `random_state = 42`
""")

model = RandomForestRegressor(n_estimators=100, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model.fit(X_train, y_train)
st.success("‚úÖ Mod√®le entra√Æn√© avec succ√®s !")

# ------------------------------------
st.header("üìä 3. Performance du mod√®le")
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

col1, col2 = st.columns(2)
col1.metric("üìà R¬≤ score", f"{r2:.3f}")
col2.metric("üìâ Erreur absolue moyenne", f"{mae:.3f}")

st.subheader("Comparaison Pr√©dictions vs R√©el (√©chantillon)")
fig_perf, ax_perf = plt.subplots()
ax_perf.scatter(y_test[:100], y_pred[:100], alpha=0.6)
ax_perf.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
ax_perf.set_xlabel("Vrai prix")
ax_perf.set_ylabel("Prix pr√©dit")
ax_perf.set_title("Pr√©dictions vs Valeurs r√©elles")
st.pyplot(fig_perf)

# ------------------------------------
st.header("üåê 4. Explicabilit√© Globale")
st.write("Analyse de l'influence moyenne des variables √† l'aide de SHAP.")

st.markdown("""
#### üìò Comment lire ce graphique ?

Ce graphique montre l'**importance moyenne** de chaque variable dans les pr√©dictions du mod√®le.

- **Chaque barre bleue** repr√©sente une variable.
- **Plus la barre est longue**, plus la variable influence fortement les pr√©dictions.
- L'importance est mesur√©e par la **valeur absolue moyenne des SHAP values** pour chaque variable.

Par exemple :
- `MedInc` (revenu m√©dian) a l‚Äôimpact moyen le plus fort sur le prix pr√©dictif.
- `Latitude`, `AveOccup` (occupation moyenne) et `Longitude` suivent.

> Ce graphique donne une **vue globale** du fonctionnement du mod√®le : quelles variables il utilise le plus en moyenne.
""")

@st.cache_resource
def get_explainer():
    return shap.TreeExplainer(model)

explainer = get_explainer()

# R√©duire la taille pour √©viter lenteurs
X_sample = X_test.iloc[:min(100, len(X_test))]
shap_values = explainer.shap_values(X_sample)

st.subheader("üîç Graphique des importances moyennes (SHAP)")
fig_global, ax_global = plt.subplots()
shap.summary_plot(shap_values, X_sample, plot_type="bar", show=False)
st.pyplot(fig_global)

# ------------------------------------
st.header("üîé 5. Explicabilit√© Locale")
index = st.slider("S√©lectionnez une observation √† expliquer :", 0, len(X_sample) - 1, 0)
individual = X_sample.iloc[[index]]

st.write("Observation s√©lectionn√©e :")
st.write(individual)

st.subheader("üìà Waterfall plot de la pr√©diction")
fig_local, ax_local = plt.subplots()
shap.plots.waterfall(shap.Explanation(
    values=shap_values[index],
    base_values=explainer.expected_value,
    data=individual.values[0],
    feature_names=individual.columns.tolist()), show=False)
st.pyplot(fig_local)