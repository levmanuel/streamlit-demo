import streamlit as st
import pandas as pd
import shap
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

st.set_page_config(page_title="ExplicabilitÃ© IA avec SHAP", layout="wide")

st.title("ğŸ§  ExplicabilitÃ© des modÃ¨les d'IA avec SHAP")
st.write("""
Bienvenue ! Cette application a pour objectif de vous expliquer les notions **d'explicabilitÃ© globale** et **locale**
des modÃ¨les d'intelligence artificielle, Ã  l'aide de **SHAP (SHapley Additive exPlanations)**.
""")

st.header("ğŸ“¦ 1. Chargement des donnÃ©es")
@st.cache_data
def load_data():
    data = fetch_california_housing(as_frame=True)
    X = data.data
    y = data.target
    return X, y

X, y = load_data()
st.write("Voici un aperÃ§u des donnÃ©es :")
st.dataframe(X.head())

st.header("ğŸ¤– 2. EntraÃ®nement du modÃ¨le")
model = RandomForestRegressor(n_estimators=100, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model.fit(X_train, y_train)
st.success("ModÃ¨le Random Forest entraÃ®nÃ© !")

st.header("ğŸŒ 3. ExplicabilitÃ© Globale")
st.write("""
L'explicabilitÃ© **globale** nous aide Ã  comprendre **quelles caractÃ©ristiques influencent le plus le modÃ¨le** en gÃ©nÃ©ral.
""")

explainer = shap.Explainer(model, X_train)
shap_values = explainer(X_test)

st.subheader("ğŸ“Š Importance moyenne des variables (globales)")
fig1, ax1 = plt.subplots()
shap.plots.bar(shap_values, max_display=10, show=False)
st.pyplot(fig1)

st.markdown("""
âœ… **InterprÃ©tation** : plus une variable a une valeur SHAP moyenne Ã©levÃ©e (en valeur absolue), plus elle contribue aux prÃ©dictions du modÃ¨le.
""")

st.header("ğŸ” 4. ExplicabilitÃ© Locale")
st.write("""
L'explicabilitÃ© **locale** s'intÃ©resse Ã  **une prÃ©diction particuliÃ¨re** : pourquoi le modÃ¨le a-t-il prÃ©dit cette valeur pour cet individu ?
""")

index = st.slider("Choisissez l'observation Ã  expliquer (entre 0 et 100)", 0, 100, 0)
individual_data = X_test.iloc[[index]]

st.write("ğŸ” CaractÃ©ristiques de l'observation sÃ©lectionnÃ©e :")
st.write(individual_data)

st.subheader("ğŸ“ˆ Valeurs SHAP pour cette observation")
fig2, ax2 = plt.subplots()
shap.plots.waterfall(shap_values[index], show=False)
st.pyplot(fig2)

st.markdown("""
âœ… **InterprÃ©tation** : le graphique en cascade montre comment chaque caractÃ©ristique influence la prÃ©diction finale par rapport Ã  la moyenne.
""")

st.info("""
ğŸ’¡ **Rappel** :
- Les **valeurs SHAP positives** poussent la prÃ©diction **vers le haut**.
- Les **valeurs SHAP nÃ©gatives** la poussent **vers le bas**.
""")

st.markdown("---")
st.caption("App crÃ©Ã©e avec â¤ï¸ par ChatGPT - SHAP + Streamlit Demo")