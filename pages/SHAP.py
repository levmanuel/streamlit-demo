import streamlit as st
import pandas as pd
import shap
import matplotlib.pyplot as plt
import numpy as np
from sklearn.datasets import fetch_california_housing
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split

st.set_page_config(page_title="SHAP & IA - ExplicabilitÃ©", layout="wide")

st.title("ğŸ§  ExplicabilitÃ© locale et globale avec SHAP")
st.write("""
Cette application explore les concepts dâ€™**explicabilitÃ© globale et locale** Ã  lâ€™aide de **SHAP**.
Nous utilisons un modÃ¨le de **Random Forest** sur le dataset *California Housing* pour prÃ©dire le prix moyen dâ€™une maison.
""")

st.header("ğŸ“¦ 1. Chargement et prÃ©paration des donnÃ©es")
@st.cache_data
def load_data():
    data = fetch_california_housing(as_frame=True)
    return data.data, data.target

X, y = load_data()
st.write("AperÃ§u des donnÃ©es :")
st.dataframe(X.head())

st.header("ğŸ§  2. ModÃ¨le utilisÃ©")
st.markdown("""
Nous utilisons un modÃ¨le **Random Forest Regressor** de Scikit-learn :
- `n_estimators = 100`
- `random_state = 42`
""")

model = RandomForestRegressor(n_estimators=100, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model.fit(X_train, y_train)
st.success("âœ… ModÃ¨le entraÃ®nÃ© avec succÃ¨s !")

st.header("ğŸ“Š 3. Performance du modÃ¨le")
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

col1, col2 = st.columns(2)
col1.metric("ğŸ“ˆ RÂ² score", f"{r2:.3f}")
col2.metric("ğŸ“‰ Erreur absolue moyenne", f"{mae:.3f}")

st.subheader("Comparaison PrÃ©dictions vs RÃ©el (Ã©chantillon)")
fig_perf, ax_perf = plt.subplots()
ax_perf.scatter(y_test[:100], y_pred[:100], alpha=0.6)
ax_perf.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
ax_perf.set_xlabel("Vrai prix")
ax_perf.set_ylabel("Prix prÃ©dit")
ax_perf.set_title("PrÃ©dictions vs Valeurs rÃ©elles")
st.pyplot(fig_perf)

st.header("ğŸŒ 4. ExplicabilitÃ© Globale")
st.write("Analyse de l'influence moyenne des variables Ã  l'aide de SHAP.")

@st.cache_resource
def compute_shap_values(model, X_sample):
    explainer = shap.TreeExplainer(model)
    return explainer.shap_values(X_sample), explainer

# âš ï¸ Limiter Ã  100 pour Ã©viter les lenteurs sur Streamlit Cloud
sample_size = min(100, X_test.shape[0])
X_sample = X_test.iloc[:sample_size]
shap_values, explainer = compute_shap_values(model, X_sample)

st.subheader("ğŸ” Graphique des importances moyennes (SHAP)")
fig_global, ax_global = plt.subplots()
shap.summary_plot(shap_values, X_sample, plot_type="bar", show=False)
st.pyplot(fig_global)

st.header("ğŸ” 5. ExplicabilitÃ© Locale")
index = st.slider("SÃ©lectionnez une observation Ã  expliquer :", 0, sample_size - 1, 0)
individual = X_sample.iloc[[index]]

st.write("Observation sÃ©lectionnÃ©e :")
st.write(individual)

st.subheader("ğŸ“ˆ Waterfall plot de la prÃ©diction")
fig_local, ax_local = plt.subplots()
shap.plots.waterfall(shap.Explanation(values=shap_values[index],
                                      base_values=explainer.expected_value,
                                      data=individual.values[0],
                                      feature_names=individual.columns.tolist()), show=False)
st.pyplot(fig_local)